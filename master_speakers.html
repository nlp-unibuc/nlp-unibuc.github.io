<!DOCTYPE html>
<html lang="en">
<head>
        <title>Natural Language Processing Master&#8217;s&nbsp;Degree</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Human Language Technologies Research Center Atom Feed" />

<meta property="og:image" content="/theme/images/logo.jpg" />
<meta property="og:title" content="Human Language Technologies Research Center" />
<meta property="og:description" content="Human Language Technologies Research Center, Faculty of Mathematics and Computer Science, University of Bucharest. Natural Language Processing. Machine Learning. Computational Linguistics. Artificial Intelligence. NLP. ML." />
<meta name="description" content="Human Language Technologies Research Center, Faculty of Mathematics and Computer Science, University of Bucharest. Natural Language Processing. Machine Learning. Computational Linguistics. Artificial Intelligence. NLP. ML." />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->

</head>

<body id="index" class="home">
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=303613546408187";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script>
        <header id="banner" class="body">
                <h1>
                <a href="/"><img src="/theme/images/logo.png" alt="HLT"> </a>
                 <a href="/">Human Language Technologies Research Center  <br> 
                 <strong>  Faculty of Mathematics and Computer Science, University of Bucharest   </strong></a></h1>
                 <nav><ul>
                    <li><a href="/master_en.html">Master's Degree</a></li>
                    <li><a href="/events.html">Events</a></li>
                    <li><a href="/people.html">People</a></li>
                    <li><a href="/projects.html">Projects</a></li>
                    <li><a href="/resources.html">Resources</a></li>
                    <li><a href="/publications.html">Publications</a></li>
                    <li><a href="/contact.html">Contact</a></li>
                </ul></nav>
        </header><!-- /#banner -->
        
<section id="content" class="body">    
    <h1 class="entry-title">Natural Language Processing Master&#8217;s&nbsp;Degree</h1>
    
    <h2><strong>Invited&nbsp;Speakers</strong></h2>
<ul>
<li>
<p>16 December (part two), 2020, 16:00.  <a href="https://tsvm.github.io/">Tsvetomila Mihaylova</a> (Instituto de Telecomunicações, Lisbon, Portugal) and <a href="http://vene.ro/">Vlad Niculae</a> (University of Amsterdam): <strong>Tutorial on Latent Structure Models for Natural Language Processing part <span class="caps">II</span></strong>.</p>
</li>
<li>
<p>9 December (part one), 2020, 16:00.  <a href="https://tsvm.github.io/">Tsvetomila Mihaylova</a> (Instituto de Telecomunicações, Lisbon, Portugal) and <a href="http://vene.ro/">Vlad Niculae</a> (University of Amsterdam): <strong>Tutorial on Latent Structure Models for Natural Language Processing part I</strong>.</p>
</li>
</ul>
<p><strong><a href="https://forms.gle/PkTGiosBwVYY1tKZ6">Register here for both&nbsp;talks.</a></strong></p>
<p><strong>Abstract:</strong> Latent structure models are a powerful tool for modelling compositional data, discovering linguistic structure, and building <span class="caps">NLP</span> pipelines. They are appealing for two main reasons: they allow incorporating structural bias during training, leading to more accurate models; and they allow discovering hidden linguistic structure, which provides better interpretability, translation, and semantic&nbsp;parsing.</p>
<p>This tutorial will cover recent advances in discrete latent structure models. We discuss their motivation, potential, and limitations, then explore in detail three strategies for designing such models: gradient approximation, reinforcement learning, and end-to-end differentiable methods. We highlight connections among all these methods, enumerating their strengths and weaknesses. The models we present and analyze have been applied to a wide variety of <span class="caps">NLP</span> tasks, including sentiment analysis, natural language inference, language modelling, machine translation, and semantic&nbsp;parsing.</p>
<p>Examples and evaluation will be covered throughout. After attending the tutorial, a practitioner will be better informed about which method is best suited for their&nbsp;problem.</p>
<p><strong>Bio:</strong> Vlad Niculae is an assistant professor in the Language Technology Lab at the University of Amsterdam. Vlad’s research lies at the intersection of machine learning and natural language processing, building upon techniques from optimization, geometry, and probability, in order to develop and analyze better models of language structures and phenomena. Vlad obtained his PhD in Computer Science from Cornell University in 2018, advised by Prof. Claire Cardie. His PhD thesis, “Learning Deep Models With Linguistically-Inspired Structure”, received the Cornell <span class="caps">CS</span> Dissertation Award. Afterwards, Vlad has worked until 2020 as a post-doctoral researcher in the DeepSPIN project (Deep Structured Prediction for Natural Language Processing) at the Instituto de Telecomunicações, Lisbon, Portugal. He is an alumnus of the University of Bucharest who was introduced to academic research by Prof. Liviu P.&nbsp;Dinu.</p>
<p><strong>Bio:</strong> Tsvetomila Mihaylova is a PhD student in the DeepSPIN project at the Instituto de Telecomunicações in Lisbon, Portugal, supervised by Vlad Niculae and André Martins. She is working on machine learning and natural language processing and her current research is related to understanding models with latent structures and trying to use them for practical applications.
She has a master’s degree in Information Retrieval from Sofia University, where she was supervised by Dr. Preslav Nakov. She was also a teaching assistant in Artificial Intelligence and has organized a shared task for fact-checking in SemEval&nbsp;2019.</p>
<p><strong>Slides:</strong> <a href="https://deep-spin.github.io/tutorial/">https://deep-spin.github.io/tutorial/</a></p>
<hr>
<ul>
<li>26 November, 2020, 16:00. <a href="http://www.cs.cornell.edu/~cristian/">Cristian Danescu-Niculescu-Mizil</a> (Cornell University): <strong>Towards an artificial intuition: Conversational markers of (anti)social dynamics</strong>.</li>
</ul>
<p><strong><a href="https://forms.gle/o7VxmEUkfvY7y4P57">Register here for the&nbsp;talk.</a></strong></p>
<p><strong>Abstract:</strong> Can conversational dynamics — the nature of the back and forth between people — predict outcomes of social interactions? This talk will describe efforts on developing an artificial intuition about ongoing conversations, by modeling the subtle pragmatic and rhetorical choices of the participants. The resulting framework distills emerging conversational patterns that can point to the nature of the social relation between interlocutors, as well as to the future trajectory of this relation.  For example, I will discuss how interactional dynamics can be used to foretell whether an online conversation will stay on track or eventually derail into personal attacks, providing community moderators several hours of prior notice before an anti-social event is likely to occur.
The data and code are available through the <a href="http://convokit.cornell.edu">Cornell Conversational Analysis Toolkit ConvoKit</a>. This talk includes joint work with Jonathan P. Chang, Lucas Dixon, Liye Fu, Yiqing Hua, Dan Jurafsky,  Lillian Lee, Jure Leskovec, Vlad Niculae, Chris Potts, Arthur Spirling, Dario Taraborelli, Nithum Thain, and Justine&nbsp;Zhang.</p>
<p><strong>Short bio:</strong> Cristian Danescu-Niculescu-Mizil is an associate professor in the information science department at Cornell University.  His research aims at developing computational methods that can lead to a better understanding of our conversational practices, supporting tools that can improve the way we communicate online.  He is the recipient of several awards—including an <span class="caps">NSF</span> <span class="caps">CAREER</span> Award, the <span class="caps">WWW</span> 2013 Best Paper Award, a <span class="caps">CSCW</span> 2017 Best Paper Award, and two Google Faculty Research Awards—and his work has been featured in popular media outlets such as The Wall Street Journal, <span class="caps">NBC</span>&#8217;s The Today Show, <span class="caps">NPR</span> and the New York&nbsp;Times.</p>
<hr>
</section>
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Powered by <a href="http://getpelican.com/">Pelican</a>. Theme
                based on <a
                    href="http://coding.smashingmagazine.com">Smashing
                    Magazine</a>.</address><!-- /#about -->
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-69680045-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>